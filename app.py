# app.py
# =========================================================
# AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro (ì™„ì„±ë³¸)
# - ì›í™” í‰ë‹¨ê°€ ì…ë ¥ + êµ­ë‚´/í•´ì™¸ í†µí™”í‘œì‹œ + ì›í™” ì†ìµ
# - RandomForest ìƒìŠ¹í™•ë¥  + ë‰´ìŠ¤ ê°ì„±(ETF/ì§€ìˆ˜ í‚¤ì›Œë“œ ëŒ€ì²´ + NewsAPI ë³´ê°•)
# - í•œêµ­ì–´ ê°ì„±(Transformer) ìë™ ì ìš©(ê°€ëŠ¥í•  ë•Œ)
# - ì…ë ¥ ìë™ URL ì €ì¥ + Reset + ì„¤ì • JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# =========================================================

import json
import re
from urllib.parse import quote_plus, unquote_plus

import numpy as np
import pandas as pd
import requests
import streamlit as st
import yfinance as yf
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import TimeSeriesSplit
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# ---------------------------
# Streamlit ê¸°ë³¸
# ---------------------------
st.set_page_config(page_title="AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro", layout="wide")
st.title("ğŸ“Š AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro")

# =========================================================
# 0) ìë™ URL ì €ì¥ ì…ë ¥ë¶€ (ì „ëµ B ìë™ ì €ì¥ + Reset + ì•ˆì „ ë¡œë“œ)
# =========================================================

DEFAULT_TICKERS = "AAPL, MSFT, NVDA, 005930.KS, BTC-KRW"
DEFAULT_BUYPRICES = "150000, 300000, 400000, 70000, 50000000"
DEFAULT_QTYS = "10, 5, 3, 10, 0.01"


def get_qp() -> dict:
    if hasattr(st, "query_params"):
        return dict(st.query_params)
    return st.experimental_get_query_params()


def set_qp(**kwargs):
    safe = {k: v for k, v in kwargs.items() if v is not None}
    if hasattr(st, "query_params"):
        st.query_params.clear()
        for k, v in safe.items():
            st.query_params[k] = v
    else:
        st.experimental_set_query_params(**safe)


def qp_get_str(qp: dict, key: str, default: str) -> str:
    if key not in qp:
        return default
    v = qp[key]
    if isinstance(v, list):
        v = v[0] if len(v) else default
    if v is None or v == "":
        return default
    try:
        return unquote_plus(str(v))
    except Exception:
        return str(v)


def enc(s: str) -> str:
    return quote_plus(s)


def mark_dirty():
    st.session_state["__qp_dirty__"] = True


def request_reset():
    st.session_state["__reset_requested__"] = True


def request_apply_loaded_settings(payload: dict):
    # ì½œë°±/ì—…ë¡œë“œ íƒ€ì´ë°ì—ì„œ ë°”ë¡œ reruní•˜ì§€ ë§ê³  í”Œë˜ê·¸ë¡œ ì²˜ë¦¬
    st.session_state["__loaded_settings__"] = payload
    st.session_state["__apply_loaded_settings__"] = True


# ì´ˆê¸° í”Œë˜ê·¸ë“¤
if "__qp_dirty__" not in st.session_state:
    st.session_state["__qp_dirty__"] = False
if "__reset_requested__" not in st.session_state:
    st.session_state["__reset_requested__"] = False
if "__apply_loaded_settings__" not in st.session_state:
    st.session_state["__apply_loaded_settings__"] = False
if "__loaded_settings__" not in st.session_state:
    st.session_state["__loaded_settings__"] = {}

# ì´ˆê¸°ê°’: URL â†’ session_state (ìµœì´ˆ 1íšŒ)
qp = get_qp()
init_tickers = qp_get_str(qp, "tickers", DEFAULT_TICKERS)
init_buy = qp_get_str(qp, "buy", DEFAULT_BUYPRICES)
init_qty = qp_get_str(qp, "qty", DEFAULT_QTYS)

if "tickers_input" not in st.session_state:
    st.session_state["tickers_input"] = init_tickers
if "buy_prices_input" not in st.session_state:
    st.session_state["buy_prices_input"] = init_buy
if "quantities_input" not in st.session_state:
    st.session_state["quantities_input"] = init_qty

# âœ… Reset ì²˜ë¦¬: ì½œë°± ë°–ì—ì„œ ì‹¤í–‰
if st.session_state["__reset_requested__"]:
    for k in ["tickers_input", "buy_prices_input", "quantities_input"]:
        if k in st.session_state:
            del st.session_state[k]

    set_qp(
        tickers=enc(DEFAULT_TICKERS),
        buy=enc(DEFAULT_BUYPRICES),
        qty=enc(DEFAULT_QTYS),
    )

    st.session_state["__qp_dirty__"] = False
    st.session_state["__reset_requested__"] = False
    st.rerun()

# âœ… JSON ì—…ë¡œë“œë¡œ ë¶ˆëŸ¬ì˜¤ê¸° ì ìš©: ì½œë°± ë°–ì—ì„œ ì‹¤í–‰
if st.session_state["__apply_loaded_settings__"]:
    loaded = st.session_state.get("__loaded_settings__", {}) or {}
    t = str(loaded.get("tickers_input", DEFAULT_TICKERS))
    b = str(loaded.get("buy_prices_input", DEFAULT_BUYPRICES))
    q = str(loaded.get("quantities_input", DEFAULT_QTYS))

    for k in ["tickers_input", "buy_prices_input", "quantities_input"]:
        if k in st.session_state:
            del st.session_state[k]

    set_qp(tickers=enc(t), buy=enc(b), qty=enc(q))

    st.session_state["__apply_loaded_settings__"] = False
    st.session_state["__loaded_settings__"] = {}
    st.rerun()

# ---------------------------
# ì…ë ¥ UI
# ---------------------------
st.subheader("ì…ë ¥ (ìë™ URL ì €ì¥)")
col1, col2, col3, col4 = st.columns([3, 3, 3, 1])

with col1:
    st.text_input("ì¢…ëª©ì½”ë“œ (ì‰¼í‘œ êµ¬ë¶„)", key="tickers_input", on_change=mark_dirty)

with col2:
    st.text_input("í‰ë‹¨ê°€ (ì›í™” ê¸°ì¤€, ì‰¼í‘œ êµ¬ë¶„)", key="buy_prices_input", on_change=mark_dirty)

with col3:
    st.text_input("ìˆ˜ëŸ‰ (ì‰¼í‘œ êµ¬ë¶„)", key="quantities_input", on_change=mark_dirty)

with col4:
    st.write("")
    st.write("")
    st.button("Reset", on_click=request_reset)

# âœ… ìë™ URL ì €ì¥ (dirtyì¼ ë•Œë§Œ, ë‹¤ë¥¼ ë•Œë§Œ set_qp)
if st.session_state["__qp_dirty__"]:
    desired_t = enc(st.session_state["tickers_input"])
    desired_b = enc(st.session_state["buy_prices_input"])
    desired_q = enc(st.session_state["quantities_input"])

    current = get_qp()
    cur_t = current.get("tickers", "")
    cur_b = current.get("buy", "")
    cur_q = current.get("qty", "")

    if isinstance(cur_t, list):
        cur_t = cur_t[0] if len(cur_t) else ""
    if isinstance(cur_b, list):
        cur_b = cur_b[0] if len(cur_b) else ""
    if isinstance(cur_q, list):
        cur_q = cur_q[0] if len(cur_q) else ""

    if (cur_t != desired_t) or (cur_b != desired_b) or (cur_q != desired_q):
        set_qp(tickers=desired_t, buy=desired_b, qty=desired_q)

    st.session_state["__qp_dirty__"] = False

st.caption("âœ… ì…ë ¥ ë³€ê²½ ì‹œ ìë™ìœ¼ë¡œ URLì— ì €ì¥ë©ë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨/ì¬ì ‘ì†/ê³µìœ í•´ë„ ë™ì¼ ì…ë ¥ ìœ ì§€")

# =========================================================
# 1) ì…ë ¥ê°’ íŒŒì‹±
# =========================================================

tickers_input = st.session_state["tickers_input"]
buy_prices_input = st.session_state["buy_prices_input"]
quantities_input = st.session_state["quantities_input"]


def safe_float_list(s: str) -> list[float]:
    out: list[float] = []
    for item in s.split(","):
        item = item.strip()
        if not item:
            out.append(0.0)
            continue
        try:
            out.append(float(item))
        except Exception:
            out.append(0.0)
    return out


tickers = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]
buy_prices_krw = safe_float_list(buy_prices_input)  # âœ… ì „ë¶€ ì›í™”ë¡œ í•´ì„
quantities = safe_float_list(quantities_input)

max_len = max(len(tickers), len(buy_prices_krw), len(quantities))
while len(tickers) < max_len:
    tickers.append("")
while len(buy_prices_krw) < max_len:
    buy_prices_krw.append(0.0)
while len(quantities) < max_len:
    quantities.append(0.0)

# =========================================================
# 2) ìœ í‹¸: Close ì¶”ì¶œ/í†µí™” íŒë³„/í‘œì‹œ
# =========================================================


def extract_close_series(data: pd.DataFrame) -> pd.Series | None:
    if data is None or len(data) == 0:
        return None

    if isinstance(data.columns, pd.MultiIndex):
        if "Close" not in data.columns.get_level_values(0):
            return None
        close_part = data.xs("Close", axis=1, level=0, drop_level=True)
        if isinstance(close_part, pd.DataFrame):
            if close_part.shape[1] == 0:
                return None
            close = close_part.iloc[:, 0]
        else:
            close = close_part
    else:
        if "Close" not in data.columns:
            return None
        close = data["Close"]
        if isinstance(close, pd.DataFrame):
            if close.shape[1] == 0:
                return None
            close = close.iloc[:, 0]

    if not isinstance(close, pd.Series):
        try:
            close = close.squeeze()
        except Exception:
            return None
        if not isinstance(close, pd.Series):
            return None

    close = close.dropna()
    if len(close) == 0:
        return None
    return close


def is_korea_ticker(ticker: str) -> bool:
    return ticker.endswith(".KS") or ticker.endswith(".KQ") or ticker.endswith(".KO")


def is_crypto_ticker(ticker: str) -> bool:
    return "-" in ticker and (ticker.endswith("-USD") or ticker.endswith("-KRW"))


def fmt_krw(x: float) -> str:
    return f"â‚©{x:,.0f}"


def fmt_usd(x: float) -> str:
    return f"${x:,.2f}"


@st.cache_data(ttl=60 * 30)
def get_usdkrw_rate() -> float:
    try:
        fx = yf.download("KRW=X", period="10d", progress=False)
        fx_close = extract_close_series(fx)
        if fx_close is None:
            return 0.0
        rate = float(fx_close.iloc[-1])
        return rate if rate > 0 else 0.0
    except Exception:
        return 0.0


usdkrw = get_usdkrw_rate()
if usdkrw == 0.0:
    st.warning("USD/KRW í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•´ì™¸ ì¢…ëª© í™˜ì‚° KRWê°€ 0ìœ¼ë¡œ í‘œì‹œë  ìˆ˜ ìˆì–´ìš”.")

# =========================================================
# 3) ê¸°ìˆ ì§€í‘œ + ì ìˆ˜
# =========================================================


def calculate_risk(vol: float) -> str:
    if vol < 0.02:
        return "ë‚®ìŒ"
    if vol < 0.05:
        return "ë³´í†µ"
    return "ë†’ìŒ"


def base_ai_score(trend: float, vol: float, mom: float) -> float:
    score = (trend * 200.0) + ((1.0 - vol) * 30.0) + (mom * 100.0) + 20.0
    return float(score)


def upgraded_ai_score(trend: float, vol: float, mom: float, prob_up: float, senti: float) -> int:
    # RF í™•ë¥ : 0.5 ê¸°ì¤€ ìµœëŒ€ Â±25ì  ì •ë„
    rf_component = (prob_up - 0.5) * 50.0
    # ë‰´ìŠ¤ ê°ì„±: ìµœëŒ€ Â±10ì  ì •ë„
    news_component = senti * 10.0
    s = base_ai_score(trend, vol, mom) + rf_component + news_component
    return int(np.clip(s, 0, 100))


def rsi(series: pd.Series, window: int = 14) -> pd.Series:
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    ma_up = up.rolling(window).mean()
    ma_down = down.rolling(window).mean()
    rs = ma_up / (ma_down.replace(0, np.nan))
    return 100 - (100 / (1 + rs))

# =========================================================
# 4) RandomForest ìƒìŠ¹í™•ë¥ 
# =========================================================


@st.cache_data(ttl=60 * 60)
def rf_up_probability(ticker: str) -> tuple[float, dict]:
    debug = {"status": "ok"}
    try:
        df = yf.download(ticker, period="2y", progress=False, auto_adjust=False)
    except Exception as e:
        return 0.0, {"status": f"download_fail: {e}"}

    close = extract_close_series(df)
    if close is None or len(close) < 140:
        return 0.0, {"status": "not_enough_data"}

    s = close.copy()
    ret1 = s.pct_change()
    vol10 = ret1.rolling(10).std()
    vol20 = ret1.rolling(20).std()

    ma5 = s.rolling(5).mean()
    ma20 = s.rolling(20).mean()
    ma60 = s.rolling(60).mean()

    feat = pd.DataFrame(
        {
            "ret1": ret1,
            "vol10": vol10,
            "vol20": vol20,
            "ma_gap_5_20": (ma5 - ma20) / ma20.replace(0, np.nan),
            "ma_gap_20_60": (ma20 - ma60) / ma60.replace(0, np.nan),
            "rsi14": rsi(s, 14),
            "mom20": (s - s.shift(20)) / s.shift(20).replace(0, np.nan),
        }
    ).dropna()

    y = (s.shift(-1).loc[feat.index] > s.loc[feat.index]).astype(int)

    X = feat.iloc[:-1]
    y = y.iloc[:-1]
    X_last = feat.iloc[[-1]]

    if len(X) < 120:
        return 0.0, {"status": "not_enough_train_rows"}

    tscv = TimeSeriesSplit(n_splits=5)
    train_idx, _ = list(tscv.split(X))[-1]
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]

    model = RandomForestClassifier(
        n_estimators=400,
        max_depth=8,
        min_samples_leaf=8,
        random_state=42,
        n_jobs=-1,
        class_weight="balanced",
    )
    model.fit(X_train, y_train)

    prob_up = float(model.predict_proba(X_last)[0, 1])
    debug["train_rows"] = int(len(X_train))
    return prob_up, debug

# =========================================================
# 5) ë‰´ìŠ¤ ê°•í™”: ETF/ì§€ìˆ˜ í‚¤ì›Œë“œ ëŒ€ì²´ + NewsAPI + í•œêµ­ì–´ ê°ì„±(ê³ ì„±ëŠ¥)
# =========================================================

analyzer = SentimentIntensityAnalyzer()

# ì‚¬ì´ë“œë°” ì˜µì…˜ (ë¬´ê±°ìš´ ê¸°ëŠ¥ì€ ì‚¬ìš©ìê°€ ëŒ ìˆ˜ ìˆê²Œ)
with st.sidebar:
    st.header("âš™ï¸ ë‰´ìŠ¤/ê°ì„± ì˜µì…˜")
    ENABLE_NEWSAPI = st.toggle("NewsAPI ë³´ê°• ì‚¬ìš©", value=True)
    ENABLE_KO_TRANSFORMER = st.toggle("í•œêµ­ì–´ ê°ì„±(Transformer) ì‚¬ìš©", value=True)
    st.caption("í•œêµ­ì–´ ê°ì„±ì€ ë¬´ê±°ìš¸ ìˆ˜ ìˆì–´ìš”. ëŠë¦¬ë©´ êº¼ë„ ë©ë‹ˆë‹¤.")

# í•œêµ­ì–´ ê°ì„± ëª¨ë¸(ë©€í‹°ë§êµ¬ì–¼, â€œê°€ëŠ¥í•  ë•Œâ€ ìë™ ì‚¬ìš©)
KOREAN_SENTIMENT_MODEL = "nlptown/bert-base-multilingual-uncased-sentiment"


def get_newsapi_key() -> str:
    try:
        return st.secrets.get("NEWSAPI_KEY", "")
    except Exception:
        return ""


NEWSAPI_KEY = get_newsapi_key()


@st.cache_data(ttl=60 * 60)
def guess_quote_type(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        qt = (info.get("quoteType") or "").upper()
        return qt if qt else "UNKNOWN"
    except Exception:
        return "UNKNOWN"


def is_index_ticker(ticker: str) -> bool:
    return ticker.startswith("^")


def is_etf_or_index(ticker: str) -> bool:
    if is_index_ticker(ticker):
        return True
    qt = guess_quote_type(ticker)
    return qt in {"ETF", "INDEX", "MUTUALFUND"}


@st.cache_data(ttl=60 * 30)
def get_keyword_for_news(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        name = info.get("longName") or info.get("shortName") or ""
        name = str(name).strip()
        if name:
            return name
    except Exception:
        pass

    if ticker.startswith("^"):
        return ticker[1:]
    return ticker


@st.cache_data(ttl=60 * 20)
def newsapi_everything(query: str, language: str | None = None, page_size: int = 20) -> tuple[list[str], dict]:
    if not (ENABLE_NEWSAPI and NEWSAPI_KEY):
        if not NEWSAPI_KEY and ENABLE_NEWSAPI:
            return [], {"status": "no_newsapi_key"}
        return [], {"status": "newsapi_disabled"}

    url = "https://newsapi.org/v2/everything"
    params = {
        "q": query,
        "pageSize": page_size,
        "sortBy": "publishedAt",
        "apiKey": NEWSAPI_KEY,
    }
    if language:
        params["language"] = language

    try:
        r = requests.get(url, params=params, timeout=8)
        data = r.json()
        if data.get("status") != "ok":
            return [], {"status": "newsapi_error", "message": data.get("message", "")}

        titles = []
        for a in data.get("articles", [])[:page_size]:
            t = (a.get("title") or "").strip()
            if t:
                titles.append(t)

        if not titles:
            return [], {"status": "newsapi_no_titles"}
        return titles, {"status": "ok", "count": len(titles)}
    except Exception as e:
        return [], {"status": "newsapi_fail", "error": str(e)}


def detect_language_simple(text: str) -> str:
    if re.search(r"[ê°€-í£]", text):
        return "ko"
    return "en"


@st.cache_resource
def get_ko_sentiment_pipe():
    # transformers/torchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì˜ˆì™¸ â†’ í˜¸ì¶œë¶€ì—ì„œ ì²˜ë¦¬
    from transformers import pipeline
    return pipeline("sentiment-analysis", model=KOREAN_SENTIMENT_MODEL)


def stars_to_compound(label: str) -> float:
    m = re.search(r"(\d)", label)
    if not m:
        return 0.0
    stars = int(m.group(1))  # 1~5
    return (stars - 3) / 2.0  # 1->-1, 3->0, 5->+1


def sentiment_compound_from_titles(titles: list[str]) -> tuple[float, str]:
    if not titles:
        return 0.0, "ì¤‘ë¦½"

    titles = titles[:10]
    joined = " ".join(titles[:3])
    lang = detect_language_simple(joined)

    if lang == "en":
        scores = []
        for t in titles:
            s = analyzer.polarity_scores(t).get("compound", 0.0)
            scores.append(float(s))
        comp = float(np.mean(scores)) if scores else 0.0
    else:
        # í•œêµ­ì–´/ë¹„ì˜ì–´: Transformer(ê°€ëŠ¥í•  ë•Œ)
        if not ENABLE_KO_TRANSFORMER:
            comp = 0.0
        else:
            try:
                pipe = get_ko_sentiment_pipe()
                preds = pipe(titles)
                vals = []
                for p in preds:
                    label = str(p.get("label", ""))
                    vals.append(stars_to_compound(label))
                comp = float(np.mean(vals)) if vals else 0.0
            except Exception:
                # torch/transformers ë¯¸ì„¤ì¹˜ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ì´ë©´ ì•ˆì „í•˜ê²Œ ì¤‘ë¦½ ì²˜ë¦¬
                comp = 0.0

    if comp > 0.05:
        lab = "ê¸ì •"
    elif comp < -0.05:
        lab = "ë¶€ì •"
    else:
        lab = "ì¤‘ë¦½"

    return comp, lab


@st.cache_data(ttl=60 * 20)
def news_sentiment_score(ticker: str, max_items: int = 12) -> tuple[float, list[str], dict]:
    """
    return: (sentiment_score(-1~+1), titles, debug)
    - yfinance ë‰´ìŠ¤ â†’ íƒ€ì´í‹€ ì—†ìœ¼ë©´ ETF/ì§€ìˆ˜ëŠ” í‚¤ì›Œë“œë¡œ NewsAPI ëŒ€ì²´
    - ê·¸ë˜ë„ ì—†ìœ¼ë©´ titles=[]ë¡œ ë°˜í™˜ (UIì—ì„œ ìˆ¨ê¹€ ì²˜ë¦¬)
    """
    # 1) yfinance í‹°ì»¤ ë‰´ìŠ¤ ìš°ì„ 
    try:
        t = yf.Ticker(ticker)
        news = getattr(t, "news", None)
    except Exception:
        news = None

    titles: list[str] = []
    if news:
        for item in news[:max_items]:
            title = (item.get("title") or "").strip()
            if title:
                titles.append(title)

    # 2) yfinance íƒ€ì´í‹€ì´ ì—†ìœ¼ë©´(= no_valid_titles) â†’ NewsAPI fallback
    if len(titles) == 0:
        if is_etf_or_index(ticker):
            kw = get_keyword_for_news(ticker)

            titles_en, dbg_en = newsapi_everything(kw, language="en", page_size=max_items)
            if titles_en:
                comp, lab = sentiment_compound_from_titles(titles_en)
                return comp, titles_en, {"status": "fallback_newsapi_etf_index", "keyword": kw, "lang": "en", "label": lab, **dbg_en}

            titles_ko, dbg_ko = newsapi_everything(kw, language="ko", page_size=max_items)
            if titles_ko:
                comp, lab = sentiment_compound_from_titles(titles_ko)
                return comp, titles_ko, {"status": "fallback_newsapi_etf_index", "keyword": kw, "lang": "ko", "label": lab, **dbg_ko}

            return 0.0, [], {"status": "no_news_after_fallback", "keyword": kw, "quoteType": guess_quote_type(ticker)}

        # ì¼ë°˜ ì¢…ëª©ë„ NewsAPIë¡œ ë³´ê°•í•˜ê³  ì‹¶ìœ¼ë©´ True
        USE_NEWSAPI_FOR_STOCKS_TOO = True
        if USE_NEWSAPI_FOR_STOCKS_TOO:
            kw = get_keyword_for_news(ticker)

            titles_en, dbg_en = newsapi_everything(kw, language="en", page_size=max_items)
            if titles_en:
                comp, lab = sentiment_compound_from_titles(titles_en)
                return comp, titles_en, {"status": "fallback_newsapi_stock", "keyword": kw, "lang": "en", "label": lab, **dbg_en}

            titles_ko, dbg_ko = newsapi_everything(kw, language="ko", page_size=max_items)
            if titles_ko:
                comp, lab = sentiment_compound_from_titles(titles_ko)
                return comp, titles_ko, {"status": "fallback_newsapi_stock", "keyword": kw, "lang": "ko", "label": lab, **dbg_ko}

            return 0.0, [], {"status": "no_news_after_fallback", "keyword": kw, "quoteType": guess_quote_type(ticker)}

        return 0.0, [], {"status": "no_valid_titles"}

    # 3) yfinance íƒ€ì´í‹€ì´ ìˆìœ¼ë©´ ê°ì„±ë¶„ì„ ìˆ˜í–‰
    comp, lab = sentiment_compound_from_titles(titles)
    return comp, titles, {"status": "ok", "source": "yfinance", "label": lab, "count": len(titles)}

# =========================================================
# 6) ë¶„ì„ ê²°ê³¼ ì¶œë ¥
# =========================================================

st.divider()
st.subheader("ë¶„ì„ ê²°ê³¼")

for i in range(max_len):
    ticker = tickers[i]
    if ticker == "":
        continue

    buy_price_krw = float(buy_prices_krw[i])  # âœ… ì›í™” í‰ë‹¨ê°€
    qty = float(quantities[i])

    # ê°€ê²© ë°ì´í„° (3ê°œì›”)
    try:
        data = yf.download(ticker, period="3mo", progress=False, auto_adjust=False)
    except Exception as e:
        st.warning(f"{ticker} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        continue

    close = extract_close_series(data)
    if close is None or len(close) < 5:
        st.warning(f"{ticker} ë°ì´í„° ë¶€ì¡±/ì¢…ê°€ ì—†ìŒ")
        continue

    # ë³€ë™ì„±/ì¶”ì„¸/ëª¨ë©˜í…€
    returns = close.pct_change().dropna()
    volatility = float(returns.std()) if len(returns) > 0 else 0.0

    ma20_val = close.rolling(20).mean().iloc[-1]
    ma60_val = close.rolling(60).mean().iloc[-1] if len(close) >= 60 else ma20_val

    ma20 = float(ma20_val) if pd.notna(ma20_val) else np.nan
    ma60 = float(ma60_val) if pd.notna(ma60_val) else np.nan

    if np.isnan(ma20) or np.isnan(ma60) or ma60 == 0.0:
        trend = 0.0
    else:
        trend = (ma20 - ma60) / ma60

    current_native = float(close.iloc[-1])
    first_native = float(close.iloc[0])
    momentum = 0.0 if first_native == 0.0 else (current_native - first_native) / first_native

    risk = calculate_risk(volatility)

    # í†µí™” ì²˜ë¦¬
    if is_korea_ticker(ticker) or (is_crypto_ticker(ticker) and ticker.endswith("-KRW")):
        current_krw = current_native
        current_usd = None
        currency_label = "KRW"
        fx_line = ""
        price_line = f"í˜„ì¬ê°€: {fmt_krw(current_krw)}"
    else:
        current_usd = current_native
        current_krw = current_usd * usdkrw if usdkrw > 0 else 0.0
        currency_label = "USDâ†’KRW"
        fx_line = f"í™˜ìœ¨(USD/KRW): {usdkrw:,.2f}" if usdkrw > 0 else "í™˜ìœ¨(USD/KRW): ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨"
        price_line = f"í˜„ì¬ê°€: {fmt_usd(current_usd)}  (í™˜ì‚° {fmt_krw(current_krw)})"

    # ì†ìµ/ìˆ˜ìµë¥  (ì›í™” ê¸°ì¤€)
    if buy_price_krw == 0.0:
        change_pct = 0.0
    else:
        change_pct = ((current_krw - buy_price_krw) / buy_price_krw) * 100.0

    eval_krw = current_krw * qty
    pnl_krw = (current_krw - buy_price_krw) * qty if buy_price_krw != 0.0 else 0.0

    if change_pct > 0:
        color = "red"
        arrow = "â–²"
    elif change_pct < 0:
        color = "blue"
        arrow = "â–¼"
    else:
        color = "gray"
        arrow = ""

    # RF + ë‰´ìŠ¤
    prob_up, rf_debug = rf_up_probability(ticker)
    senti, titles, news_debug = news_sentiment_score(ticker)

    ai_score = upgraded_ai_score(trend, volatility, momentum, prob_up, senti)

    prob_pct = prob_up * 100.0
    senti_label = "ê¸ì •" if senti > 0.05 else ("ë¶€ì •" if senti < -0.05 else "ì¤‘ë¦½")

    # âœ… ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ë‰´ìŠ¤ ë¼ì¸ ìì²´ë¥¼ ìˆ¨ê¹€
    news_line = ""
    if titles:
        news_line = f"- ë‰´ìŠ¤ ê°ì„±(ì œëª© ê¸°ë°˜): **{senti_label} ({senti:+.2f})**\n"

    st.markdown(
        f"""
---
### {ticker}  <span style="font-size:14px; color:#666;">[{currency_label}]</span>

{price_line}  
{fx_line}  
í‰ë‹¨ê°€(ì›í™” ì…ë ¥): {fmt_krw(buy_price_krw)} / ìˆ˜ëŸ‰: {qty:g}  
í‰ê°€ê¸ˆì•¡(ì›í™”): {fmt_krw(eval_krw)}  
í‰ê°€ì†ìµ(ì›í™”): {fmt_krw(pnl_krw)}  

<span style='color:{color}; font-size:20px; font-weight:bold;'>
{arrow} ìˆ˜ìµë¥ (ì›í™” ê¸°ì¤€): {change_pct:.2f}%
</span>  

**AI ì ìˆ˜(ì—…ê·¸ë ˆì´ë“œ): {ai_score}ì **  
- RF ìƒìŠ¹í™•ë¥ (ë‹¤ìŒ ê±°ë˜ì¼): **{prob_pct:.1f}%**
{news_line}- ë¦¬ìŠ¤í¬(ë³€ë™ì„±): **{risk}**
""",
        unsafe_allow_html=True,
    )

    with st.expander(f"ğŸ” {ticker} ìƒì„¸(ëª¨ë¸/ë‰´ìŠ¤) ë³´ê¸°"):
        st.write("**RandomForest ìƒíƒœ**:", rf_debug)

        # âœ… ë‰´ìŠ¤ê°€ ìˆì„ ë•Œë§Œ ë³´ì—¬ì£¼ê¸° (ìš”ì²­í•˜ì‹  â€˜ê¹”ë”í•˜ê²Œ ìˆ¨ê¹€â€™)
        if titles:
            st.write("**ë‰´ìŠ¤ ìƒíƒœ**:", news_debug)
            st.write("**ìµœê·¼ ë‰´ìŠ¤ ì œëª©(ì¼ë¶€)**")
            for t in titles[:10]:
                st.write(f"- {t}")

# =========================================================
# 7) ì„¤ì • JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° (ì˜µì…˜: URLì´ ê¸¸ì–´ì§ˆ ë•Œ ì¶”ì²œ)
# =========================================================

with st.expander("ğŸ’¾ ì„¤ì • JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° (URLì´ ê¸¸ì–´ì§ˆ ë•Œ ì¶”ì²œ)"):
    current_settings = {
        "tickers_input": st.session_state["tickers_input"],
        "buy_prices_input": st.session_state["buy_prices_input"],
        "quantities_input": st.session_state["quantities_input"],
    }
    settings_json = json.dumps(current_settings, ensure_ascii=False, indent=2)

    st.download_button(
        label="â¬‡ï¸ í˜„ì¬ ì„¤ì • JSON ë‹¤ìš´ë¡œë“œ",
        data=settings_json.encode("utf-8"),
        file_name="portfolio_settings.json",
        mime="application/json",
    )

    uploaded = st.file_uploader("â¬†ï¸ ì„¤ì • JSON ì—…ë¡œë“œ", type=["json"])
    if uploaded is not None:
        try:
            loaded = json.loads(uploaded.read().decode("utf-8"))
            request_apply_loaded_settings(loaded)
            st.success("ì„¤ì •ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ì ìš©ì„ ìœ„í•´ í™”ë©´ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì„¤ì • íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
