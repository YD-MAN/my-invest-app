# app.py
# =========================================================
# AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro (ìµœì¢…)
# - URL + localStorage í•˜ì´ë¸Œë¦¬ë“œ ì…ë ¥ ì €ì¥/ë³µì›(ì™„ì „ ìë™)
# - ì›í™” í‰ë‹¨ê°€ ì…ë ¥ + êµ­ë‚´/í•´ì™¸ í†µí™” í‘œì‹œ + ì›í™” ì†ìµ
# - í™˜ìœ¨ ì•ˆì •í™” + ìˆ˜ë™ í™˜ìœ¨ ì˜¤ë²„ë¼ì´ë“œ
# - RandomForest ìƒìŠ¹í™•ë¥  + ë‰´ìŠ¤ ê°ì„±(ETF/ì§€ìˆ˜ í‚¤ì›Œë“œ ëŒ€ì²´ + NewsAPI ë³´ê°•)
# - í•œêµ­ì–´ ê°ì„±(Transformer) ê°€ëŠ¥í•  ë•Œ ìë™ ì ìš©
# - í¬íŠ¸í´ë¦¬ì˜¤ í•©ì‚°(ì´ í‰ê°€ê¸ˆì•¡/ì†ìµ/ë¹„ì¤‘/ì†ìµ ì°¨íŠ¸) - Streamlit ë‚´ì¥ ì°¨íŠ¸(ì¶”ê°€ ì„¤ì¹˜ ç„¡)
# =========================================================

import json
import re
from urllib.parse import quote_plus, unquote_plus

import numpy as np
import pandas as pd
import requests
import streamlit as st
import yfinance as yf
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import TimeSeriesSplit
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# âœ… localStorageìš©(ì—†ì–´ë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ try/except)
HAS_JS_EVAL = False
try:
    from streamlit_js_eval import streamlit_js_eval
    HAS_JS_EVAL = True
except Exception:
    HAS_JS_EVAL = False

# ---------------------------
# Streamlit ê¸°ë³¸
# ---------------------------
st.set_page_config(page_title="AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro", layout="wide")
st.title("ğŸ“Š AI í¬íŠ¸í´ë¦¬ì˜¤ ë§¤ë‹ˆì € Pro")

# =========================================================
# 0) URL + localStorage í•˜ì´ë¸Œë¦¬ë“œ ì €ì¥/ë³µì›
# =========================================================

DEFAULT_TICKERS = "AAPL, MSFT, NVDA, 005930.KS, BTC-KRW"
DEFAULT_BUYPRICES = "150000, 300000, 400000, 70000, 50000000"
DEFAULT_QTYS = "10, 5, 3, 10, 0.01"

LS_KEY = "ai_portfolio_manager_pro_v1"  # localStorage key (ë²„ì „ ë°”ê¾¸ë©´ ìƒˆë¡œ ì €ì¥ë¨)


def get_qp() -> dict:
    if hasattr(st, "query_params"):
        return dict(st.query_params)
    return st.experimental_get_query_params()


def set_qp(**kwargs):
    safe = {k: v for k, v in kwargs.items() if v is not None}
    if hasattr(st, "query_params"):
        st.query_params.clear()
        for k, v in safe.items():
            st.query_params[k] = v
    else:
        st.experimental_set_query_params(**safe)


def qp_get_str(qp: dict, key: str, default: str) -> str:
    if key not in qp:
        return default
    v = qp[key]
    if isinstance(v, list):
        v = v[0] if len(v) else default
    if v is None or v == "":
        return default
    try:
        return unquote_plus(str(v))
    except Exception:
        return str(v)


def enc(s: str) -> str:
    return quote_plus(s)


def mark_dirty():
    st.session_state["__qp_dirty__"] = True


def request_reset():
    st.session_state["__reset_requested__"] = True


def request_apply_loaded_settings(payload: dict):
    st.session_state["__loaded_settings__"] = payload
    st.session_state["__apply_loaded_settings__"] = True


def load_from_localstorage() -> dict:
    """
    localStorageì—ì„œ JSON ë¬¸ìì—´ì„ ì½ì–´ dictë¡œ ë°˜í™˜.
    streamlit-js-evalì´ ì—†ìœ¼ë©´ {} ë°˜í™˜.
    """
    if not HAS_JS_EVAL:
        return {}
    try:
        raw = streamlit_js_eval(
            js_expressions=f"localStorage.getItem('{LS_KEY}')",
            want_output=True,
            key="LS_GET",
        )
        if raw is None:
            return {}
        if isinstance(raw, str) and raw.strip() == "":
            return {}
        # rawê°€ JSON ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ
        try:
            return json.loads(raw)
        except Exception:
            return {}
    except Exception:
        return {}


def save_to_localstorage(payload: dict):
    """
    localStorageì— JSON ì €ì¥.
    streamlit-js-evalì´ ì—†ìœ¼ë©´ ì•„ë¬´ ê²ƒë„ ì•ˆ í•¨.
    """
    if not HAS_JS_EVAL:
        return
    try:
        # JS ë¬¸ìì—´ ì•ˆì „í•˜ê²Œ ë„£ê¸° ìœ„í•´ JSONì„ ë‹¤ì‹œ dumps
        s = json.dumps(payload, ensure_ascii=False)
        # JS ë¬¸ìì—´ ë¦¬í„°ëŸ´ë¡œ ì•ˆì „í•˜ê²Œ ë„£ê¸°(ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„)
        s_js = s.replace("\\", "\\\\").replace("'", "\\'")
        streamlit_js_eval(
            js_expressions=f"localStorage.setItem('{LS_KEY}', '{s_js}')",
            want_output=False,
            key="LS_SET",
        )
    except Exception:
        pass


# í”Œë˜ê·¸ ì´ˆê¸°í™”
if "__qp_dirty__" not in st.session_state:
    st.session_state["__qp_dirty__"] = False
if "__reset_requested__" not in st.session_state:
    st.session_state["__reset_requested__"] = False
if "__apply_loaded_settings__" not in st.session_state:
    st.session_state["__apply_loaded_settings__"] = False
if "__loaded_settings__" not in st.session_state:
    st.session_state["__loaded_settings__"] = {}
if "__ls_bootstrapped__" not in st.session_state:
    st.session_state["__ls_bootstrapped__"] = False

# 1) URL ì½ê¸°
qp = get_qp()
url_has_any = ("tickers" in qp) or ("buy" in qp) or ("qty" in qp)

init_tickers = qp_get_str(qp, "tickers", DEFAULT_TICKERS)
init_buy = qp_get_str(qp, "buy", DEFAULT_BUYPRICES)
init_qty = qp_get_str(qp, "qty", DEFAULT_QTYS)

# 2) URLì´ ë¹„ì–´ìˆê±°ë‚˜ í™ˆìŠ¤í¬ë¦°ì—ì„œ ìœ ì‹¤ëœ ê²½ìš° â†’ localStorageì—ì„œ ë³µì›(ìµœì´ˆ 1íšŒë§Œ)
#    - URLì´ ì´ë¯¸ ìˆìœ¼ë©´ URLì„ ìš°ì„ (ê³µìœ  ë§í¬/ë¶ë§ˆí¬ ì¼ê´€ì„±)
if (not url_has_any) and (not st.session_state["__ls_bootstrapped__"]):
    ls_data = load_from_localstorage()
    if isinstance(ls_data, dict) and ls_data.get("tickers_input") and ls_data.get("buy_prices_input") and ls_data.get("quantities_input"):
        init_tickers = str(ls_data["tickers_input"])
        init_buy = str(ls_data["buy_prices_input"])
        init_qty = str(ls_data["quantities_input"])
        # URLë„ ê°™ì´ ë§ì¶°ì£¼ë©´ ì´í›„ ê³µìœ /ìƒˆë¡œê³ ì¹¨ ì¼ê´€ì„±ì´ ì¢‹ì•„ì§
        set_qp(tickers=enc(init_tickers), buy=enc(init_buy), qty=enc(init_qty))
    st.session_state["__ls_bootstrapped__"] = True

# ì…ë ¥ state ì´ˆê¸°ê°’(ìµœì´ˆ 1íšŒ)
if "tickers_input" not in st.session_state:
    st.session_state["tickers_input"] = init_tickers
if "buy_prices_input" not in st.session_state:
    st.session_state["buy_prices_input"] = init_buy
if "quantities_input" not in st.session_state:
    st.session_state["quantities_input"] = init_qty

# Reset(ì½œë°± ë°–)
if st.session_state["__reset_requested__"]:
    for k in ["tickers_input", "buy_prices_input", "quantities_input"]:
        if k in st.session_state:
            del st.session_state[k]

    # URL reset
    set_qp(tickers=enc(DEFAULT_TICKERS), buy=enc(DEFAULT_BUYPRICES), qty=enc(DEFAULT_QTYS))

    # localStorage resetë„ ê°™ì´
    save_to_localstorage(
        {
            "tickers_input": DEFAULT_TICKERS,
            "buy_prices_input": DEFAULT_BUYPRICES,
            "quantities_input": DEFAULT_QTYS,
        }
    )

    st.session_state["__qp_dirty__"] = False
    st.session_state["__reset_requested__"] = False
    st.rerun()

# JSON ì—…ë¡œë“œ ì ìš©(ì½œë°± ë°–)
if st.session_state["__apply_loaded_settings__"]:
    loaded = st.session_state.get("__loaded_settings__", {}) or {}
    t = str(loaded.get("tickers_input", DEFAULT_TICKERS))
    b = str(loaded.get("buy_prices_input", DEFAULT_BUYPRICES))
    q = str(loaded.get("quantities_input", DEFAULT_QTYS))

    for k in ["tickers_input", "buy_prices_input", "quantities_input"]:
        if k in st.session_state:
            del st.session_state[k]

    set_qp(tickers=enc(t), buy=enc(b), qty=enc(q))
    save_to_localstorage({"tickers_input": t, "buy_prices_input": b, "quantities_input": q})

    st.session_state["__apply_loaded_settings__"] = False
    st.session_state["__loaded_settings__"] = {}
    st.rerun()

# ---------------------------
# ì…ë ¥ UI
# ---------------------------
st.subheader("ì…ë ¥ (URL + localStorage ìë™ ì €ì¥)")
col1, col2, col3, col4 = st.columns([3, 3, 3, 1])

with col1:
    st.text_input("ì¢…ëª©ì½”ë“œ (ì‰¼í‘œ êµ¬ë¶„)", key="tickers_input", on_change=mark_dirty)

with col2:
    st.text_input("í‰ë‹¨ê°€ (ì›í™” ê¸°ì¤€, ì‰¼í‘œ êµ¬ë¶„)", key="buy_prices_input", on_change=mark_dirty)

with col3:
    st.text_input("ìˆ˜ëŸ‰ (ì‰¼í‘œ êµ¬ë¶„)", key="quantities_input", on_change=mark_dirty)

with col4:
    st.write("")
    st.write("")
    st.button("Reset", on_click=request_reset)

# URL ìë™ ì €ì¥(dirtyì¼ ë•Œë§Œ)
if st.session_state["__qp_dirty__"]:
    desired_t = enc(st.session_state["tickers_input"])
    desired_b = enc(st.session_state["buy_prices_input"])
    desired_q = enc(st.session_state["quantities_input"])

    current = get_qp()
    cur_t = current.get("tickers", "")
    cur_b = current.get("buy", "")
    cur_q = current.get("qty", "")

    if isinstance(cur_t, list):
        cur_t = cur_t[0] if len(cur_t) else ""
    if isinstance(cur_b, list):
        cur_b = cur_b[0] if len(cur_b) else ""
    if isinstance(cur_q, list):
        cur_q = cur_q[0] if len(cur_q) else ""

    if (cur_t != desired_t) or (cur_b != desired_b) or (cur_q != desired_q):
        set_qp(tickers=desired_t, buy=desired_b, qty=desired_q)

    st.session_state["__qp_dirty__"] = False

# âœ… localStorageëŠ” ë§¤ë²ˆ(í˜¹ì€ ê°’ ë³€ê²½ ì§í›„) ì €ì¥í•´ë„ ë¶€ë‹´ì´ ì‘ì•„ì„œ í•­ìƒ ìµœì‹ ìœ¼ë¡œ ë§ì¶¤
save_to_localstorage(
    {
        "tickers_input": st.session_state["tickers_input"],
        "buy_prices_input": st.session_state["buy_prices_input"],
        "quantities_input": st.session_state["quantities_input"],
    }
)

st.caption("âœ… URLê³¼ ë¸Œë¼ìš°ì €(localStorage)ì— ë™ì‹œì— ì €ì¥ë©ë‹ˆë‹¤. ëª¨ë°”ì¼ í™ˆìŠ¤í¬ë¦°(ë¶ë§ˆí¬)ì—ì„œë„ ì…ë ¥ ìœ ì§€ê°€ í›¨ì”¬ ì•ˆì •ì ì…ë‹ˆë‹¤.")

# =========================================================
# 1) íŒŒì‹±
# =========================================================

tickers_input = st.session_state["tickers_input"]
buy_prices_input = st.session_state["buy_prices_input"]
quantities_input = st.session_state["quantities_input"]


def safe_float_list(s: str) -> list[float]:
    out: list[float] = []
    for item in s.split(","):
        item = item.strip()
        if not item:
            out.append(0.0)
            continue
        try:
            out.append(float(item))
        except Exception:
            out.append(0.0)
    return out


tickers = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]
buy_prices_krw = safe_float_list(buy_prices_input)
quantities = safe_float_list(quantities_input)

max_len = max(len(tickers), len(buy_prices_krw), len(quantities))
while len(tickers) < max_len:
    tickers.append("")
while len(buy_prices_krw) < max_len:
    buy_prices_krw.append(0.0)
while len(quantities) < max_len:
    quantities.append(0.0)

# =========================================================
# 2) ìœ í‹¸
# =========================================================

def extract_close_series(data: pd.DataFrame) -> pd.Series | None:
    if data is None or len(data) == 0:
        return None

    if isinstance(data.columns, pd.MultiIndex):
        if "Close" not in data.columns.get_level_values(0):
            return None
        close_part = data.xs("Close", axis=1, level=0, drop_level=True)
        if isinstance(close_part, pd.DataFrame):
            if close_part.shape[1] == 0:
                return None
            close = close_part.iloc[:, 0]
        else:
            close = close_part
    else:
        if "Close" not in data.columns:
            return None
        close = data["Close"]
        if isinstance(close, pd.DataFrame):
            if close.shape[1] == 0:
                return None
            close = close.iloc[:, 0]

    if not isinstance(close, pd.Series):
        try:
            close = close.squeeze()
        except Exception:
            return None
        if not isinstance(close, pd.Series):
            return None

    close = close.dropna()
    if len(close) == 0:
        return None
    return close


def is_korea_ticker(ticker: str) -> bool:
    return ticker.endswith(".KS") or ticker.endswith(".KQ") or ticker.endswith(".KO")


def is_crypto_ticker(ticker: str) -> bool:
    return "-" in ticker and (ticker.endswith("-USD") or ticker.endswith("-KRW"))


def fmt_krw(x: float) -> str:
    return f"â‚©{x:,.0f}"


def fmt_usd(x: float) -> str:
    return f"${x:,.2f}"

# =========================================================
# 3) í™˜ìœ¨(USD/KRW) ì•ˆì •í™” + ìˆ˜ë™ ì˜¤ë²„ë¼ì´ë“œ
# =========================================================

@st.cache_data(ttl=60 * 30)
def try_fetch_usdkrw() -> tuple[float, str]:
    try:
        fx = yf.download("KRW=X", period="1mo", progress=False)
        c = extract_close_series(fx)
        if c is not None and len(c) > 0:
            v = float(c.iloc[-1])
            if v > 0:
                return v, "KRW=X(download)"
    except Exception:
        pass

    try:
        fx = yf.Ticker("KRW=X").history(period="1mo")
        c = extract_close_series(fx)
        if c is not None and len(c) > 0:
            v = float(c.iloc[-1])
            if v > 0:
                return v, "KRW=X(history)"
    except Exception:
        pass

    try:
        fx = yf.download("USDKRW=X", period="1mo", progress=False)
        c = extract_close_series(fx)
        if c is not None and len(c) > 0:
            v = float(c.iloc[-1])
            if v > 0:
                return v, "USDKRW=X(download)"
    except Exception:
        pass

    return 0.0, "fail"


usdkrw_auto, usdkrw_src = try_fetch_usdkrw()

with st.sidebar:
    st.header("ğŸ’± í™˜ìœ¨ ì„¤ì •")
    manual_fx = st.number_input(
        "USD/KRW ìˆ˜ë™ ì…ë ¥(0ì´ë©´ ìë™)",
        min_value=0.0,
        value=0.0,
        step=1.0,
        help="ìë™ í™˜ìœ¨ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ 0ì´ë©´ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
    )

if manual_fx > 0:
    usdkrw = float(manual_fx)
    usdkrw_src_final = "manual"
else:
    usdkrw = float(usdkrw_auto)
    usdkrw_src_final = usdkrw_src

if usdkrw == 0.0:
    st.warning("USD/KRW í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•´ì™¸ ì¢…ëª© í™˜ì‚° KRWê°€ 0ìœ¼ë¡œ í‘œì‹œë  ìˆ˜ ìˆì–´ìš”. (ì‚¬ì´ë“œë°” ìˆ˜ë™ í™˜ìœ¨ ì…ë ¥ ê°€ëŠ¥)")
else:
    st.info(f"USD/KRW í™˜ìœ¨: {usdkrw:,.2f}  (source: {usdkrw_src_final})")

# =========================================================
# 4) ê¸°ìˆ ì§€í‘œ + ì ìˆ˜
# =========================================================

def calculate_risk(vol: float) -> str:
    if vol < 0.02:
        return "ë‚®ìŒ"
    if vol < 0.05:
        return "ë³´í†µ"
    return "ë†’ìŒ"


def base_ai_score(trend: float, vol: float, mom: float) -> float:
    score = (trend * 200.0) + ((1.0 - vol) * 30.0) + (mom * 100.0) + 20.0
    return float(score)


def upgraded_ai_score(trend: float, vol: float, mom: float, prob_up: float, senti: float) -> int:
    rf_component = (prob_up - 0.5) * 50.0
    news_component = senti * 10.0
    s = base_ai_score(trend, vol, mom) + rf_component + news_component
    return int(np.clip(s, 0, 100))


def rsi(series: pd.Series, window: int = 14) -> pd.Series:
    delta = series.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    ma_up = up.rolling(window).mean()
    ma_down = down.rolling(window).mean()
    rs = ma_up / (ma_down.replace(0, np.nan))
    return 100 - (100 / (1 + rs))

# =========================================================
# 5) RandomForest ìƒìŠ¹í™•ë¥ 
# =========================================================

@st.cache_data(ttl=60 * 60)
def rf_up_probability(ticker: str) -> tuple[float, dict]:
    try:
        df = yf.download(ticker, period="2y", progress=False, auto_adjust=False)
    except Exception as e:
        return 0.0, {"status": f"download_fail: {e}"}

    close = extract_close_series(df)
    if close is None or len(close) < 140:
        return 0.0, {"status": "not_enough_data"}

    s = close.copy()
    ret1 = s.pct_change()
    vol10 = ret1.rolling(10).std()
    vol20 = ret1.rolling(20).std()
    ma5 = s.rolling(5).mean()
    ma20 = s.rolling(20).mean()
    ma60 = s.rolling(60).mean()

    feat = pd.DataFrame(
        {
            "ret1": ret1,
            "vol10": vol10,
            "vol20": vol20,
            "ma_gap_5_20": (ma5 - ma20) / ma20.replace(0, np.nan),
            "ma_gap_20_60": (ma20 - ma60) / ma60.replace(0, np.nan),
            "rsi14": rsi(s, 14),
            "mom20": (s - s.shift(20)) / s.shift(20).replace(0, np.nan),
        }
    ).dropna()

    y = (s.shift(-1).loc[feat.index] > s.loc[feat.index]).astype(int)

    X = feat.iloc[:-1]
    y = y.iloc[:-1]
    X_last = feat.iloc[[-1]]

    if len(X) < 120:
        return 0.0, {"status": "not_enough_train_rows"}

    tscv = TimeSeriesSplit(n_splits=5)
    train_idx, _ = list(tscv.split(X))[-1]
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]

    model = RandomForestClassifier(
        n_estimators=400,
        max_depth=8,
        min_samples_leaf=8,
        random_state=42,
        n_jobs=-1,
        class_weight="balanced",
    )
    model.fit(X_train, y_train)

    prob_up = float(model.predict_proba(X_last)[0, 1])
    return prob_up, {"status": "ok", "train_rows": int(len(X_train))}

# =========================================================
# 6) ë‰´ìŠ¤ ê°ì„±: ETF/ì§€ìˆ˜ í‚¤ì›Œë“œ ëŒ€ì²´ + NewsAPI + í•œêµ­ì–´(ê°€ëŠ¥ ì‹œ)
# =========================================================

analyzer = SentimentIntensityAnalyzer()

with st.sidebar:
    st.header("ğŸ“° ë‰´ìŠ¤/ê°ì„± ì˜µì…˜")
    ENABLE_NEWSAPI = st.toggle("NewsAPI ë³´ê°• ì‚¬ìš©", value=True)
    ENABLE_KO_TRANSFORMER = st.toggle("í•œêµ­ì–´ ê°ì„±(Transformer) ì‚¬ìš©", value=True)
    st.caption("í•œêµ­ì–´ ê°ì„±ì€ ë¬´ê±°ìš¸ ìˆ˜ ìˆì–´ìš”. ëŠë¦¬ë©´ ë„ì„¸ìš”.")

KOREAN_SENTIMENT_MODEL = "nlptown/bert-base-multilingual-uncased-sentiment"


def get_newsapi_key() -> str:
    try:
        return st.secrets.get("NEWSAPI_KEY", "")
    except Exception:
        return ""


NEWSAPI_KEY = get_newsapi_key()


@st.cache_data(ttl=60 * 60)
def guess_quote_type(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        qt = (info.get("quoteType") or "").upper()
        return qt if qt else "UNKNOWN"
    except Exception:
        return "UNKNOWN"


def is_etf_or_index(ticker: str) -> bool:
    if ticker.startswith("^"):
        return True
    qt = guess_quote_type(ticker)
    return qt in {"ETF", "INDEX", "MUTUALFUND"}


@st.cache_data(ttl=60 * 30)
def get_keyword_for_news(ticker: str) -> str:
    try:
        info = yf.Ticker(ticker).info
        name = info.get("longName") or info.get("shortName") or ""
        name = str(name).strip()
        if name:
            return name
    except Exception:
        pass
    return ticker[1:] if ticker.startswith("^") else ticker


@st.cache_data(ttl=60 * 20)
def newsapi_everything(query: str, language: str | None, page_size: int) -> tuple[list[str], dict]:
    if not (ENABLE_NEWSAPI and NEWSAPI_KEY):
        if ENABLE_NEWSAPI and not NEWSAPI_KEY:
            return [], {"status": "no_newsapi_key"}
        return [], {"status": "newsapi_disabled"}

    url = "https://newsapi.org/v2/everything"
    params = {
        "q": query,
        "pageSize": page_size,
        "sortBy": "publishedAt",
        "apiKey": NEWSAPI_KEY,
    }
    if language:
        params["language"] = language

    try:
        r = requests.get(url, params=params, timeout=8)
        data = r.json()
        if data.get("status") != "ok":
            return [], {"status": "newsapi_error", "message": data.get("message", "")}

        titles = []
        for a in data.get("articles", [])[:page_size]:
            t = (a.get("title") or "").strip()
            if t:
                titles.append(t)

        if not titles:
            return [], {"status": "newsapi_no_titles"}
        return titles, {"status": "ok", "count": len(titles)}
    except Exception as e:
        return [], {"status": "newsapi_fail", "error": str(e)}


def detect_language_simple(text: str) -> str:
    return "ko" if re.search(r"[ê°€-í£]", text) else "en"


@st.cache_resource
def get_ko_sentiment_pipe():
    from transformers import pipeline
    return pipeline("sentiment-analysis", model=KOREAN_SENTIMENT_MODEL)


def stars_to_compound(label: str) -> float:
    m = re.search(r"(\d)", label)
    if not m:
        return 0.0
    stars = int(m.group(1))
    return (stars - 3) / 2.0


def sentiment_compound_from_titles(titles: list[str]) -> tuple[float, str]:
    if not titles:
        return 0.0, "ì¤‘ë¦½"

    titles = titles[:10]
    joined = " ".join(titles[:3])
    lang = detect_language_simple(joined)

    if lang == "en":
        vals = [float(analyzer.polarity_scores(t).get("compound", 0.0)) for t in titles]
        comp = float(np.mean(vals)) if vals else 0.0
    else:
        if not ENABLE_KO_TRANSFORMER:
            comp = 0.0
        else:
            try:
                pipe = get_ko_sentiment_pipe()
                preds = pipe(titles)
                vals = [stars_to_compound(str(p.get("label", ""))) for p in preds]
                comp = float(np.mean(vals)) if vals else 0.0
            except Exception:
                comp = 0.0

    if comp > 0.05:
        lab = "ê¸ì •"
    elif comp < -0.05:
        lab = "ë¶€ì •"
    else:
        lab = "ì¤‘ë¦½"
    return comp, lab


@st.cache_data(ttl=60 * 20)
def news_sentiment_score(ticker: str, max_items: int = 12) -> tuple[float, list[str], dict]:
    try:
        news = getattr(yf.Ticker(ticker), "news", None)
    except Exception:
        news = None

    titles = []
    if news:
        for item in news[:max_items]:
            title = (item.get("title") or "").strip()
            if title:
                titles.append(title)

    if len(titles) == 0:
        kw = get_keyword_for_news(ticker)

        if is_etf_or_index(ticker):
            t_en, dbg_en = newsapi_everything(kw, "en", max_items)
            if t_en:
                comp, lab = sentiment_compound_from_titles(t_en)
                return comp, t_en, {"status": "fallback_newsapi_etf_index", "keyword": kw, "lang": "en", "label": lab, **dbg_en}

            t_ko, dbg_ko = newsapi_everything(kw, "ko", max_items)
            if t_ko:
                comp, lab = sentiment_compound_from_titles(t_ko)
                return comp, t_ko, {"status": "fallback_newsapi_etf_index", "keyword": kw, "lang": "ko", "label": lab, **dbg_ko}

            return 0.0, [], {"status": "no_news_after_fallback", "keyword": kw, "quoteType": guess_quote_type(ticker)}

        USE_NEWSAPI_FOR_STOCKS_TOO = True
        if USE_NEWSAPI_FOR_STOCKS_TOO:
            t_en, dbg_en = newsapi_everything(kw, "en", max_items)
            if t_en:
                comp, lab = sentiment_compound_from_titles(t_en)
                return comp, t_en, {"status": "fallback_newsapi_stock", "keyword": kw, "lang": "en", "label": lab, **dbg_en}

            t_ko, dbg_ko = newsapi_everything(kw, "ko", max_items)
            if t_ko:
                comp, lab = sentiment_compound_from_titles(t_ko)
                return comp, t_ko, {"status": "fallback_newsapi_stock", "keyword": kw, "lang": "ko", "label": lab, **dbg_ko}

            return 0.0, [], {"status": "no_news_after_fallback", "keyword": kw, "quoteType": guess_quote_type(ticker)}

        return 0.0, [], {"status": "no_valid_titles"}

    comp, lab = sentiment_compound_from_titles(titles)
    return comp, titles, {"status": "ok", "source": "yfinance", "label": lab, "count": len(titles)}

# =========================================================
# 7) ë¶„ì„ + í¬íŠ¸í´ë¦¬ì˜¤ í•©ì‚°/ì°¨íŠ¸
# =========================================================

st.divider()
st.subheader("ë¶„ì„ ê²°ê³¼")

rows = []

for i in range(max_len):
    ticker = tickers[i]
    if ticker == "":
        continue

    buy_price_krw = float(buy_prices_krw[i])
    qty = float(quantities[i])

    try:
        data = yf.download(ticker, period="3mo", progress=False, auto_adjust=False)
    except Exception as e:
        st.warning(f"{ticker} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        continue

    close = extract_close_series(data)
    if close is None or len(close) < 5:
        st.warning(f"{ticker} ë°ì´í„° ë¶€ì¡±/ì¢…ê°€ ì—†ìŒ")
        continue

    returns = close.pct_change().dropna()
    volatility = float(returns.std()) if len(returns) > 0 else 0.0

    ma20_val = close.rolling(20).mean().iloc[-1]
    ma60_val = close.rolling(60).mean().iloc[-1] if len(close) >= 60 else ma20_val
    ma20 = float(ma20_val) if pd.notna(ma20_val) else np.nan
    ma60 = float(ma60_val) if pd.notna(ma60_val) else np.nan
    trend = 0.0 if (np.isnan(ma20) or np.isnan(ma60) or ma60 == 0.0) else (ma20 - ma60) / ma60

    current_native = float(close.iloc[-1])
    first_native = float(close.iloc[0])
    momentum = 0.0 if first_native == 0.0 else (current_native - first_native) / first_native

    risk = calculate_risk(volatility)

    if is_korea_ticker(ticker) or (is_crypto_ticker(ticker) and ticker.endswith("-KRW")):
        current_krw = current_native
        currency_label = "KRW"
        fx_line = ""
        price_line = f"í˜„ì¬ê°€: {fmt_krw(current_krw)}"
    else:
        current_usd = current_native
        current_krw = current_usd * usdkrw if usdkrw > 0 else 0.0
        currency_label = "USDâ†’KRW"
        fx_line = f"í™˜ìœ¨(USD/KRW): {usdkrw:,.2f}  (source: {usdkrw_src_final})" if usdkrw > 0 else "í™˜ìœ¨(USD/KRW): ì—†ìŒ(ìˆ˜ë™ ì…ë ¥ í•„ìš”)"
        price_line = f"í˜„ì¬ê°€: {fmt_usd(current_usd)}  (í™˜ì‚° {fmt_krw(current_krw)})"

    change_pct = 0.0 if buy_price_krw == 0.0 else ((current_krw - buy_price_krw) / buy_price_krw) * 100.0
    eval_krw = current_krw * qty
    pnl_krw = (current_krw - buy_price_krw) * qty if buy_price_krw != 0.0 else 0.0

    color = "red" if change_pct > 0 else ("blue" if change_pct < 0 else "gray")
    arrow = "â–²" if change_pct > 0 else ("â–¼" if change_pct < 0 else "")

    prob_up, rf_debug = rf_up_probability(ticker)
    senti, titles, news_debug = news_sentiment_score(ticker)
    ai_score = upgraded_ai_score(trend, volatility, momentum, prob_up, senti)

    prob_pct = prob_up * 100.0
    senti_label = "ê¸ì •" if senti > 0.05 else ("ë¶€ì •" if senti < -0.05 else "ì¤‘ë¦½")

    news_line = ""
    if titles:
        news_line = f"- ë‰´ìŠ¤ ê°ì„±(ì œëª© ê¸°ë°˜): **{senti_label} ({senti:+.2f})**\n"

    st.markdown(
        f"""
---
### {ticker}  <span style="font-size:14px; color:#666;">[{currency_label}]</span>

{price_line}  
{fx_line}  
í‰ë‹¨ê°€(ì›í™” ì…ë ¥): {fmt_krw(buy_price_krw)} / ìˆ˜ëŸ‰: {qty:g}  
í‰ê°€ê¸ˆì•¡(ì›í™”): {fmt_krw(eval_krw)}  
í‰ê°€ì†ìµ(ì›í™”): {fmt_krw(pnl_krw)}  

<span style='color:{color}; font-size:20px; font-weight:bold;'>
{arrow} ìˆ˜ìµë¥ (ì›í™” ê¸°ì¤€): {change_pct:.2f}%
</span>  

**AI ì ìˆ˜(ì—…ê·¸ë ˆì´ë“œ): {ai_score}ì **  
- RF ìƒìŠ¹í™•ë¥ (ë‹¤ìŒ ê±°ë˜ì¼): **{prob_pct:.1f}%**
{news_line}- ë¦¬ìŠ¤í¬(ë³€ë™ì„±): **{risk}**
""",
        unsafe_allow_html=True,
    )

    with st.expander(f"ğŸ” {ticker} ìƒì„¸(ëª¨ë¸/ë‰´ìŠ¤) ë³´ê¸°"):
        st.write("**RandomForest ìƒíƒœ**:", rf_debug)
        if titles:
            st.write("**ë‰´ìŠ¤ ìƒíƒœ**:", news_debug)
            st.write("**ìµœê·¼ ë‰´ìŠ¤ ì œëª©(ì¼ë¶€)**")
            for t in titles[:10]:
                st.write(f"- {t}")

    rows.append(
        {
            "Ticker": ticker,
            "Currency": currency_label,
            "Qty": qty,
            "Buy_KRW": buy_price_krw,
            "Now_KRW": current_krw,
            "Eval_KRW": eval_krw,
            "PnL_KRW": pnl_krw,
            "Return_%": change_pct,
            "AI_Score": ai_score,
            "RF_Up_%": prob_pct,
        }
    )

st.divider()
st.subheader("ğŸ“Œ í¬íŠ¸í´ë¦¬ì˜¤ í•©ì‚°")

if len(rows) == 0:
    st.info("í‘œì‹œí•  í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
else:
    df = pd.DataFrame(rows)

    total_eval = float(df["Eval_KRW"].sum())
    total_pnl = float(df["PnL_KRW"].sum())
    total_buy = total_eval - total_pnl
    total_return = (total_pnl / total_buy) * 100.0 if total_buy != 0 else 0.0

    c1, c2, c3 = st.columns(3)
    c1.metric("ì´ í‰ê°€ê¸ˆì•¡(ì›í™”)", fmt_krw(total_eval))
    c2.metric("ì´ í‰ê°€ì†ìµ(ì›í™”)", fmt_krw(total_pnl))
    c3.metric("ì´ ìˆ˜ìµë¥ (ì›í™” ê¸°ì¤€)", f"{total_return:.2f}%")

    show_cols = ["Ticker", "Currency", "Qty", "Buy_KRW", "Now_KRW", "Eval_KRW", "PnL_KRW", "Return_%", "AI_Score", "RF_Up_%"]
    st.dataframe(df[show_cols].sort_values("Eval_KRW", ascending=False), use_container_width=True)

    st.subheader("ë¹„ì¤‘ ì°¨íŠ¸ (í‰ê°€ê¸ˆì•¡ ê¸°ì¤€)")
    w = df[["Ticker", "Eval_KRW"]].copy()
    w = w[w["Eval_KRW"] > 0].sort_values("Eval_KRW", ascending=False)
    if len(w) == 0:
        st.info("ë¹„ì¤‘ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤(í‰ê°€ê¸ˆì•¡ì´ 0 ì´í•˜).")
    else:
        st.bar_chart(w.set_index("Ticker"), height=320)

    st.subheader("ì†ìµ ì°¨íŠ¸ (ì›í™”)")
    p = df[["Ticker", "PnL_KRW"]].copy().set_index("Ticker")
    st.bar_chart(p, height=320)

# =========================================================
# 8) ì„¤ì • JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
# =========================================================
with st.expander("ğŸ’¾ ì„¤ì • JSON ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° (URLì´ ê¸¸ì–´ì§ˆ ë•Œ ì¶”ì²œ)"):
    current_settings = {
        "tickers_input": st.session_state["tickers_input"],
        "buy_prices_input": st.session_state["buy_prices_input"],
        "quantities_input": st.session_state["quantities_input"],
    }
    settings_json = json.dumps(current_settings, ensure_ascii=False, indent=2)

    st.download_button(
        label="â¬‡ï¸ í˜„ì¬ ì„¤ì • JSON ë‹¤ìš´ë¡œë“œ",
        data=settings_json.encode("utf-8"),
        file_name="portfolio_settings.json",
        mime="application/json",
    )

    uploaded = st.file_uploader("â¬†ï¸ ì„¤ì • JSON ì—…ë¡œë“œ", type=["json"])
    if uploaded is not None:
        try:
            loaded = json.loads(uploaded.read().decode("utf-8"))
            request_apply_loaded_settings(loaded)
            st.success("ì„¤ì •ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ì ìš©ì„ ìœ„í•´ í™”ë©´ì„ ê°±ì‹ í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì„¤ì • íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜: {e}")
